---
title: "1. 기획 & 데이터 설계"
layout: single
sidebar:
  nav: main
permalink: /projects/deep-learning/planning/
author_profile: true
entries_layout: list
category: planning
toc: true
toc_label: "Contents"
---


## 🎯 프로젝트 선정 배경

이번 스터디의 5월 프로젝트 주제로 **딥러닝 기반 이미지 처리**를 선정하였다.  
그 이유는 다음과 같다.

- 팀원 다수가 이미지 처리 경험을 보유하고 있어 **기술 진입 장벽이 낮다**.  
- 단순 전처리를 넘어서, **결함 분류 및 탐지 알고리즘까지 확장 가능한 주제**가 필요했다.  
- 특히 **반도체 머신비전 분야**는 결함을 얼마나 빠르고 정확하게 탐지하느냐에 초점을 맞추기 때문에,  
  프로젝트의 **목표가 명확하고 집중도가 높다**.  
- 공개된 문서나 논문에 **정확도 및 처리 속도에 대한 기준 지표**가 명시되어 있어,  
  실제 실습 결과를 기반으로 **객관적인 성과 비교가 가능하다**.

이러한 요소들은 학습 목표와 실무 연계를 동시에 충족할 수 있는 조건이 되며,  
**딥러닝 데이터 설계 및 실험 환경 구성에 적합한 주제**로 판단하였다.

## 🔍 프로젝트 사전 리서치

프로젝트를 시작하기에 앞서, 산업 현장에서 머신비전이 실제로 어떻게 운영되고 있는지를 리서치했다.  
특히 **AI 모델 개발과 현장 운영 간의 간극**, 그리고 **향후 모델 개발 자동화 가능성**에 주목했다.

---

## 🧠 모델 개발은 느리고 복잡하다

비전 검사 모델을 만들기 위해서는 실제 데이터를 수집하고, 라벨링을 진행해야 한다.  
이후 모델을 학습시키고, 성능을 검증하고 개선하는 과정을 반복한다.

이런 일련의 과정을 완료하는 데에는 **수주에서 수개월**이 걸린다.  
라벨링 품질, 도메인 전문성, 하드웨어 리소스 등에 따라 기간이 더 길어지기도 한다.

그러나 최근에는 **AI의 발달로 이 개발 시간이 단축될 수 있는 가능성**도 보인다.

---

### 🤖 모델 개발 자동화에 대한 추론

다음은 나의 주장이다:

- 최근 추세: **MCP 기반 LLM이 다양한 플랫폼에 이식 중**
- 사례: Visual Studio에 탑재된 **Cursor AI**가 **시니어 개발자의 생산성을 대폭 향상**
- 효과: 기존에는 주니어 개발자 여러 명이 필요했던 작업이,  
  이제는 시니어 한 명만으로도 처리 가능

> 📌 결론적으로, **비전 검사 시스템을 개발하는 Cognex 같은 기업**이 MCP 기반 모델링 AI를 도입한다면,  
기존 비전팀 전체가 수개월 동안 작업하던 모델 개발이 **시니어 1인에 의해 수일 만에 완료될 가능성**도 있다.

> 📝 개인적인 주장이다. 이와 관련한 내용은 별도 포스트로 분리 예정이다다
---

## ⚡ 모델 실행은 빠르고 안정적이다

모델이 일단 완성되면, **운영 단계에서는 속도와 안정성이 최우선**이다.

- 사전 정의된 결함만을 대상으로
- GPU 가속을 통해 **초당 수백~수천 장의 이미지 처리**
- **현장에서는 모델이 변경되지 않고 고정 상태로 반복 사용**

운영자는 모델의 내부 구조나 학습 방식에 개입하지 않으며,  
검사 장비에 고정된 형태로 실시간 분석을 수행한다.

---

## 📌 반도체 다이 검사 성능 요건

프로젝트 타깃으로 설정한 **반도체 다이 수준의 결함 분류**에서는 다음과 같은 성능 요건이 요구된다:

- **결함 분류 처리 시간**: **200ms 이하 / 다이 1개 기준**

---

## 📊 성능 기준 요약

| 항목                | 내용                        |
|---------------------|-----------------------------|
| 다이 크기           | 약 10mm × 10mm              |
| 카메라 분해능       | 픽셀당 약 2μm               |
| 이미지 해상도       | 약 250만 픽셀 (예: 2500×1000) |
| 단일 이미지 용량    | 약 23MB                     |
| 분류 속도 요구사항 | 1다이당 200ms 이하         |

> 📝 이와 관련한 세부 기술자료는 별도 포스트로 정리 예정

---

## 🎯 산업용 비전 검사의 목표

산업 현장에서 비전 검사의 목적은 분명하다:

- **빠르고 일관된 품질 검사**
- **불확실성 없이 신뢰할 수 있는 프로세스 유지**

이를 위해선 모델 개발과 운영 사이의 분리를 이해하고,  
장기적으로는 **모델 학습 AI 자동화와 최적화 가능성**도 함께 고려해야 한다.

## 💡 프로젝트 개요

목표: 반도체 웨이퍼 표면검사에 쓰이는 이미지 처리 알고리즘을 연구

데이터: DAGM 2007 – 난이도가 낮다, 인공 생성된 유사 웨이퍼 이미지

---

## 🧭 문제 정의

이미지 처리 알고리즘은 난이도에 따라 세 분류로 나눌 수 있다. 

| 유형 | 설명 | 난이도 | 추천 기술 및 모델 |
| --- | --- | --- | --- |
| 🧠 분류 (Classification) | 이미지에 불량이 있는지 여부만 판단 | ★☆☆ | `ResNet`, `EfficientNet` |
| 📍 위치 검출 (Detection) | 이미지 내 불량의 위치와 경계 표시 | ★★☆ | `YOLOv5`,  `Faster R-CNN` |
| ⚠️ 이상 감지 (Anomaly Detection) | 정상이 아닌 패턴을 자동 식별
(라벨 없이 비지도 학습) | ★★★ | `AutoEncoder`, `GANomaly` |

## 📂 문제 정의에 따른 데이터 구성 방식의 차이

모델 구조가 다르면 라벨링 방식과 데이터 디렉토리 구조도 달라진다.

분류(Classification) 모델과 검출(Detection) 모델은 서로 다른 방식으로 데이터를 구성해야 한다.

모델 구조에 따라 데이터 구성 방식이 어떻게 달라지는지 궁금하다면  
➡️ [데이터 구성 가이드 포스트 보기](https://git-rich-club.github.io/planning/data-structure-guidelines/)


---

## 🦋 Augmentation의 필요성

모델 학습에는 다양한 데이터를 생성하기 위해 Augmentation이 필요하다. 

아래는 Augmentation 의 부연 설명과 전처리의 필요성에 관한 포스트이다. 

➡️ [Augmentation이 필요한 이유 보기](https://git-rich-club.github.io/planning/augmentation/)

---

## 🧾 데이터셋 구성

- Train / Validation / Test 분할 비율을 정하고, 클래스 불균형 문제를 해결해야 한다.
- 교차 검증(K-fold) 전략을 사용할 경우, 데이터 누수(Data Leakage)를 방지할 수 있도록 주의한다.

**고려 포인트**
- 데이터셋 간 도메인 격차(domain drift)를 고려
- 불균형 데이터 처리: 샘플링, 클래스 가중치 등 활용
- 누수 방지: 이미지 중복 여부, 순서 기반 분할 방지

---

향후 "모델링 & 학습 평가", "배포 & 운영" 단계에서 이 기획 내용이 기반이 된다.  
기획 단계에서 탄탄한 구조를 세우는 것이 전체 프로젝트 완성도를 좌우한다.
